{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 08 - Hyperparameter Tuning with Optuna\n",
    "\n",
    "This notebook uses Optuna to optimize XGBoost hyperparameters for the volume forecasting task.\n",
    "\n",
    "## Optimization Strategy\n",
    "\n",
    "- **Method**: Bayesian optimization with TPE (Tree-structured Parzen Estimator)\n",
    "- **Objective**: Minimize mean MAE across walk-forward validation folds\n",
    "- **Trials**: 50 trials with median pruning\n",
    "- **Parameters**: n_estimators, max_depth, learning_rate, min_child_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from datetime import date\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.pruners import MedianPruner\n",
    "\n",
    "# Add src to path for imports\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root / \"src\"))\n",
    "\n",
    "# Import evaluation tools\n",
    "from volume_forecast.evaluation import WalkForwardValidator\n",
    "\n",
    "# Import models\n",
    "from volume_forecast.models import XGBoostModel\n",
    "\n",
    "# Import feature pipeline\n",
    "from volume_forecast.features import FeaturePipeline\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "print(f\"Optuna version: {optuna.__version__}\")\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## 2. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_path = project_root / \"data\" / \"raw\" / \"synthetic_volumes.csv\"\n",
    "df = pd.read_csv(data_path, parse_dates=[\"date\"])\n",
    "df = df.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "print(f\"Loaded data: {len(df)} rows\")\n",
    "print(f\"Date range: {df['date'].min().date()} to {df['date'].max().date()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Feature Pipeline\n",
    "pipeline = FeaturePipeline(\n",
    "    date_column='date',\n",
    "    target_columns=['daily_logins'],\n",
    "    include_events=True,\n",
    "    include_football=True,\n",
    ")\n",
    "df_features = pipeline.fit_transform(df)\n",
    "print(f\"Features generated: {len(pipeline.get_feature_names())} columns\")\n",
    "print(f\"Dataset shape: {df_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "TARGET = 'daily_logins'\n",
    "DATE_COLUMN = 'date'\n",
    "\n",
    "# External features for enhanced model (same as notebook 07)\n",
    "EXTERNAL_FEATURES = [\n",
    "    # Temporal features\n",
    "    'day_of_week', 'is_weekend', 'day_of_week_sin', 'day_of_week_cos',\n",
    "    'month', 'month_sin', 'month_cos',\n",
    "    \n",
    "    # Rolling statistics\n",
    "    'daily_logins_rolling_mean_7', 'daily_logins_rolling_mean_14', 'daily_logins_rolling_mean_30',\n",
    "    'daily_logins_rolling_std_7', 'daily_logins_rolling_std_14', 'daily_logins_rolling_std_30',\n",
    "    \n",
    "    # Event flags (same-day)\n",
    "    'is_bank_holiday', 'is_racing_event', 'is_tennis_event',\n",
    "    'is_boxing_event', 'is_football_match', 'event_importance',\n",
    "    \n",
    "    # Lead indicators (upcoming events)\n",
    "    'any_event_tomorrow', 'any_event_in_2_days', 'any_event_in_3_days',\n",
    "    'bank_holiday_tomorrow', 'bank_holiday_in_2_days', 'bank_holiday_in_3_days',\n",
    "    'football_tomorrow', 'football_in_2_days', 'football_in_3_days',\n",
    "    \n",
    "    # Lag indicators (past events)\n",
    "    'any_event_yesterday', 'any_event_2_days_ago',\n",
    "    'bank_holiday_yesterday', 'bank_holiday_2_days_ago',\n",
    "    'football_yesterday', 'football_2_days_ago',\n",
    "]\n",
    "\n",
    "print(f\"External features: {len(EXTERNAL_FEATURES)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 3. Define Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create validator (same settings as notebook 07)\n",
    "validator = WalkForwardValidator(\n",
    "    min_train_size=365,\n",
    "    test_size=7,\n",
    "    step_size=7\n",
    ")\n",
    "\n",
    "n_folds = validator.get_n_splits(df_features, date_column=DATE_COLUMN)\n",
    "print(f\"Walk-forward validation: {n_folds} folds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.Trial) -> float:\n",
    "    \"\"\"Optuna objective function for XGBoost hyperparameter optimization.\n",
    "    \n",
    "    Returns mean MAE across walk-forward validation folds.\n",
    "    \"\"\"\n",
    "    # Sample hyperparameters\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "    }\n",
    "    \n",
    "    # Create model with sampled parameters\n",
    "    model = XGBoostModel(\n",
    "        n_estimators=params['n_estimators'],\n",
    "        max_depth=params['max_depth'],\n",
    "        learning_rate=params['learning_rate'],\n",
    "        lags=[1, 7, 14],\n",
    "        external_features=EXTERNAL_FEATURES,\n",
    "        name='XGBoost_Tuning'\n",
    "    )\n",
    "    \n",
    "    # Run walk-forward validation\n",
    "    fold_results = validator.validate(\n",
    "        model=model,\n",
    "        df=df_features,\n",
    "        target=TARGET,\n",
    "        date_column=DATE_COLUMN,\n",
    "        feature_columns=EXTERNAL_FEATURES + [DATE_COLUMN]\n",
    "    )\n",
    "    \n",
    "    # Calculate mean MAE\n",
    "    mae_values = [r['metrics']['mae'] for r in fold_results]\n",
    "    mean_mae = np.mean(mae_values)\n",
    "    \n",
    "    return mean_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 4. Run Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Optuna study\n",
    "study = optuna.create_study(\n",
    "    direction='minimize',\n",
    "    sampler=TPESampler(seed=42),\n",
    "    pruner=MedianPruner(n_startup_trials=10)\n",
    ")\n",
    "\n",
    "print(\"Starting hyperparameter optimization...\")\n",
    "print(f\"Trials: 50\")\n",
    "print(f\"Folds per trial: {n_folds}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run optimization with progress callback\n",
    "def callback(study: optuna.Study, trial: optuna.trial.FrozenTrial):\n",
    "    if trial.number % 5 == 0 or trial.number == 0:\n",
    "        print(f\"Trial {trial.number:3d}: MAE = {trial.value:.2f} | Best so far: {study.best_value:.2f}\")\n",
    "\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=50,\n",
    "    callbacks=[callback],\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Optimization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## 5. Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display best parameters\n",
    "print(\"=\"*60)\n",
    "print(\"BEST HYPERPARAMETERS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nBest MAE: {study.best_value:.2f}\")\n",
    "print(f\"\\nBest Parameters:\")\n",
    "for param, value in study.best_params.items():\n",
    "    print(f\"  {param}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot optimization history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Optimization history\n",
    "ax1 = axes[0]\n",
    "trials = [t.number for t in study.trials]\n",
    "values = [t.value for t in study.trials]\n",
    "best_values = [min(values[:i+1]) for i in range(len(values))]\n",
    "\n",
    "ax1.scatter(trials, values, alpha=0.5, label='Trial MAE')\n",
    "ax1.plot(trials, best_values, 'r-', linewidth=2, label='Best MAE')\n",
    "ax1.set_xlabel('Trial')\n",
    "ax1.set_ylabel('MAE')\n",
    "ax1.set_title('Optimization History', fontsize=12, fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Parameter importance\n",
    "ax2 = axes[1]\n",
    "importances = optuna.importance.get_param_importances(study)\n",
    "params = list(importances.keys())\n",
    "values = list(importances.values())\n",
    "\n",
    "ax2.barh(params, values, color='steelblue')\n",
    "ax2.set_xlabel('Importance')\n",
    "ax2.set_title('Parameter Importance', fontsize=12, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show top 10 trials\n",
    "print(\"\\nTop 10 Trials:\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "trials_df = study.trials_dataframe()\n",
    "trials_df = trials_df.sort_values('value').head(10)\n",
    "display_cols = ['number', 'value', 'params_n_estimators', 'params_max_depth', \n",
    "                'params_learning_rate', 'params_min_child_weight']\n",
    "trials_df[display_cols].round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## 6. Validate Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tuned model with best parameters\n",
    "best_params = study.best_params\n",
    "\n",
    "tuned_model = XGBoostModel(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    lags=[1, 7, 14],\n",
    "    external_features=EXTERNAL_FEATURES,\n",
    "    name='XGBoost_Tuned'\n",
    ")\n",
    "\n",
    "# Create default model for comparison\n",
    "default_model = XGBoostModel(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    lags=[1, 7, 14],\n",
    "    external_features=EXTERNAL_FEATURES,\n",
    "    name='XGBoost_Default'\n",
    ")\n",
    "\n",
    "print(\"Models created for comparison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run full validation on both models\n",
    "print(\"Running full validation...\")\n",
    "\n",
    "results = {}\n",
    "for model in [default_model, tuned_model]:\n",
    "    fold_results = validator.validate(\n",
    "        model=model,\n",
    "        df=df_features,\n",
    "        target=TARGET,\n",
    "        date_column=DATE_COLUMN,\n",
    "        feature_columns=EXTERNAL_FEATURES + [DATE_COLUMN]\n",
    "    )\n",
    "    \n",
    "    mae_values = [r['metrics']['mae'] for r in fold_results]\n",
    "    mape_values = [r['metrics']['mape'] for r in fold_results]\n",
    "    \n",
    "    results[model.name] = {\n",
    "        'mae_mean': np.mean(mae_values),\n",
    "        'mae_std': np.std(mae_values),\n",
    "        'mape_mean': np.mean(mape_values),\n",
    "        'mape_std': np.std(mape_values),\n",
    "    }\n",
    "\n",
    "print(\"Validation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display comparison\n",
    "print(\"=\"*70)\n",
    "print(\"MODEL COMPARISON: Default vs Tuned\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(f\"  MAE:  {metrics['mae_mean']:.2f} (+/- {metrics['mae_std']:.2f})\")\n",
    "    print(f\"  MAPE: {metrics['mape_mean']:.2f}% (+/- {metrics['mape_std']:.2f}%)\")\n",
    "\n",
    "# Calculate improvement\n",
    "default_mae = results['XGBoost_Default']['mae_mean']\n",
    "tuned_mae = results['XGBoost_Tuned']['mae_mean']\n",
    "improvement = ((default_mae - tuned_mae) / default_mae) * 100\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"IMPROVEMENT: {improvement:.1f}% reduction in MAE\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## 7. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best parameters to JSON\n",
    "output_path = project_root / \"data\" / \"processed\" / \"best_xgboost_params.json\"\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "params_to_save = {\n",
    "    'best_params': study.best_params,\n",
    "    'best_mae': study.best_value,\n",
    "    'n_trials': len(study.trials),\n",
    "    'default_comparison': {\n",
    "        'default_mae': results['XGBoost_Default']['mae_mean'],\n",
    "        'tuned_mae': results['XGBoost_Tuned']['mae_mean'],\n",
    "        'improvement_pct': improvement\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump(params_to_save, f, indent=2)\n",
    "\n",
    "print(f\"Best parameters saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display final summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nBest Parameters:\")\n",
    "for param, value in study.best_params.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  {param}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"  {param}: {value}\")\n",
    "\n",
    "print(f\"\\nPerformance:\")\n",
    "print(f\"  Default MAE:  {results['XGBoost_Default']['mae_mean']:.2f}\")\n",
    "print(f\"  Tuned MAE:    {results['XGBoost_Tuned']['mae_mean']:.2f}\")\n",
    "print(f\"  Improvement:  {improvement:.1f}%\")\n",
    "\n",
    "print(f\"\\nDefault MAPE:  {results['XGBoost_Default']['mape_mean']:.2f}%\")\n",
    "print(f\"Tuned MAPE:    {results['XGBoost_Tuned']['mape_mean']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**End of Notebook 08 - Hyperparameter Tuning**\n",
    "\n",
    "Use the best parameters in notebook 07 by updating the XGBoost_Enhanced model configuration."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
